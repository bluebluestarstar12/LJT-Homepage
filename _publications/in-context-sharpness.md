---
title: "In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation"
collection: publications
permalink: /publication/in-context-sharpness
excerpt: 'This paper proposes a novel method for mitigating hallucinations in language models by analyzing the in-context sharpness of their internal representations.'
date: 2024-07-01
venue: 'ICML'
paperurl: 'https://arxiv.org/abs/2402.08225'
citation: 'Chen, S., Xiong, M., Liu, J., Wu, Z., Xiao, T., Gao, S., & He, J. (2024). In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation. In *Proceedings of the 41st International Conference on Machine Learning*.'
---
[Download paper here](https://arxiv.org/abs/2402.08225)

Recommended citation: Chen, S., Xiong, M., Liu, J., Wu, Z., Xiao, T., Gao, S., & He, J. (2024). In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation. In *Proceedings of the 41st International Conference on Machine Learning*.
